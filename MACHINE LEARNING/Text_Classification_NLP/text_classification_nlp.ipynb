{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8985be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/sayalideshmukh/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sayalideshmukh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/sayalideshmukh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sayalideshmukh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from 'austen-emma.txt': [Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n",
      "\n",
      "List of strings (words) from 'austen-emma.txt': ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "Number of words in 'austen-emma.txt': 192427\n",
      "\n",
      "List of sentences (first sentence) from 'austen-emma.txt': ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']']\n",
      "First 100 sources in the Gutenberg corpus: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "\n",
      "First 1000 characters from 'austen-emma.txt':\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.  Between _them_ it was more the intimacy\n",
      "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
      "office of governess, the mildness o\n",
      "Sample sentences from 'austen-emma.txt':\n",
      "['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.', \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\", 'Her mother\\nhad died too long ago for her to have more than an indistinct\\nremembrance of her caresses; and her place had been supplied\\nby an excellent woman as governess, who had fallen little short\\nof a mother in affection.', \"Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\\nless as a governess than a friend, very fond of both daughters,\\nbut particularly of Emma.\", 'Between _them_ it was more the intimacy\\nof sisters.']\n",
      "\n",
      "Words in the first sentence of 'austen-emma.txt':\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n",
      "\n",
      "Total number of words in 'austen-emma.txt': 191855\n",
      "Sample words from 'austen-emma.txt': ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "List of English stopwords in NLTK:\n",
      "{'if', 'from', 'll', 'i', \"she's\", 'my', 'before', 'had', 'has', 'weren', \"shan't\", 'during', 'with', 'which', 'until', 'doing', 'mustn', 'did', \"wasn't\", 'will', \"don't\", 'didn', 'you', 'but', 'there', \"it's\", \"didn't\", 'am', \"you've\", 'do', 'himself', 'hasn', 'it', 't', 'any', 'should', 'can', 'too', 'now', 'nor', 'not', \"doesn't\", 'whom', 'down', 'ain', 'a', 'under', \"hadn't\", 'those', 'does', 'then', \"you're\", 'of', 'over', 'is', 'just', \"hasn't\", 'so', 'once', 'your', 'into', 'hadn', 'more', 'no', 've', 'him', 'as', 'they', 'hers', 'ours', 'themselves', \"wouldn't\", 'yourselves', 'y', 'd', 'or', \"won't\", 'm', 'these', \"haven't\", 'where', 'couldn', \"shouldn't\", 'that', 'how', \"isn't\", 'been', 'them', 'off', 'have', 's', 're', \"needn't\", \"you'll\", 'this', 'the', 'are', 'only', \"you'd\", 'own', \"couldn't\", 'doesn', 'don', 'what', 'and', 'ourselves', 'here', 'than', 'for', \"that'll\", \"should've\", \"aren't\", 'very', 'aren', 'we', 'shan', 'when', 'why', 'were', 'being', 'all', 'herself', 'some', 'theirs', 'each', 'won', 'yourself', 'shouldn', 'by', 'through', 'above', 'mightn', 'against', \"weren't\", 'after', 'ma', 'same', 'most', 'both', 'up', 'other', 'about', 'wasn', 'o', 'further', 'be', 'few', 'isn', 'who', 'such', 'an', 'out', \"mightn't\", 'on', 'yours', 'having', 'needn', 'in', 'because', 'haven', 'myself', 'his', 'between', 'below', 'he', 'their', \"mustn't\", 'our', 'her', 'was', 'while', 'me', 'wouldn', 'its', 'to', 'at', 'she', 'itself', 'again'}\n",
      "\n",
      "Total number of stopwords: 179\n",
      "\n",
      "Sample of stopwords: ['if', 'from', 'll', 'i', \"she's\", 'my', 'before', 'had', 'has', 'weren', \"shan't\", 'during', 'with', 'which', 'until', 'doing', 'mustn', 'did', \"wasn't\", 'will']\n",
      "Initial tokenized sentences (first 2 sentences):\n",
      "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.'], ['She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.']]\n",
      "\n",
      "Flattened list of words:\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich']\n",
      "\n",
      "Lowercased and removed stopwords:\n",
      "['[', 'emma', 'jane', 'austen', '1816', ']', 'volume', 'chapter', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'rich', ',', 'comfortable', 'home', 'happy']\n",
      "\n",
      "Lemmatized words (final processed list):\n",
      "['emma', 'jane', 'austen', 'volume', 'chapter', 'emma', 'woodhouse', 'handsome', 'clever', 'rich', 'comfortable', 'home', 'happy', 'disposition', 'seemed', 'unite', 'best', 'blessing', 'existence', 'lived']\n",
      "Processed Text Sample: ['emma', 'jane', 'austen', 'volume', 'chapter', 'emma', 'woodhouse', 'handsome', 'clever', 'rich', 'comfortable', 'home', 'happy', 'disposition', 'seemed', 'unite', 'best', 'blessing', 'existence', 'lived', 'nearly', 'year', 'world', 'little', 'distress', 'vex', 'youngest', 'two', 'daughter', 'affectionate']\n",
      "Word Frequency Sample: [('emma', 860), ('could', 836), ('would', 818), ('miss', 600), ('must', 566), ('harriet', 500), ('much', 484), ('said', 483), ('thing', 456), ('one', 451)]\n",
      "Vocabulary: ['1816' '_one_' '_them_' '_we_' '_you_' 'able' 'absence' 'accepted'\n",
      " 'account' 'acquaintance']\n",
      "Bag of Words Matrix Sample: [[1 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Naive Bayes Classification Accuracy: 0.3\n",
      "Length of sentences_test: 20\n",
      "Length of y_pred: 20\n",
      "Output saved as 'nlp_assignment_output.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Load a text from Gutenberg corpus\n",
    "text = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "\n",
    "\n",
    "# Load the Gutenberg corpus\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Load a text from Gutenberg corpus\n",
    "text = gutenberg.raw('austen-emma.txt')\n",
    "print(\"Sample from 'austen-emma.txt':\", text[:500])  # Display first 500 characters of 'austen-emma.txt'\n",
    "\n",
    "# Returns a list of strings (words in the 'austen-emma.txt' text)\n",
    "gutenberg_words = gutenberg.words('austen-emma.txt')\n",
    "print(\"\\nList of strings (words) from 'austen-emma.txt':\", gutenberg_words[:10])  # Show first 10 words\n",
    "\n",
    "# Number of words in the Gutenberg corpus file\n",
    "print(\"Number of words in 'austen-emma.txt':\", len(gutenberg_words))\n",
    "\n",
    "# Returns a list of list of strings (sentences in the 'austen-emma.txt' text)\n",
    "gutenberg_sentences = gutenberg.sents('austen-emma.txt')\n",
    "print(\"\\nList of sentences (first sentence) from 'austen-emma.txt':\", gutenberg_sentences[0])  # First sentence\n",
    "\n",
    "# Display the first 100 sources (file IDs) in the Gutenberg corpus\n",
    "gutenberg_sources = gutenberg.fileids()\n",
    "print(\"First 100 sources in the Gutenberg corpus:\", gutenberg_sources[:100])\n",
    "\n",
    "# Load a specific text from the Gutenberg corpus (for example, 'austen-emma.txt')\n",
    "text = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "# Display the first 1000 characters of the selected text\n",
    "print(\"\\nFirst 1000 characters from 'austen-emma.txt':\")\n",
    "print(text[:1000])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sentence Tokenization: Split the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "print(\"Sample sentences from 'austen-emma.txt':\")\n",
    "print(sentences[:5])  # Display the first 5 sentences\n",
    "\n",
    "# Word Tokenization: Split the first sentence into words\n",
    "words_in_first_sentence = nltk.word_tokenize(sentences[0])\n",
    "print(\"\\nWords in the first sentence of 'austen-emma.txt':\")\n",
    "print(words_in_first_sentence)\n",
    "\n",
    "# Word Tokenization for the entire text (optional)\n",
    "# This can be useful if you want a list of all words in the text\n",
    "all_words = nltk.word_tokenize(text)\n",
    "print(\"\\nTotal number of words in 'austen-emma.txt':\", len(all_words))\n",
    "print(\"Sample words from 'austen-emma.txt':\", all_words[:10])  # Display the first 10 words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Display the list of stopwords\n",
    "print(\"List of English stopwords in NLTK:\")\n",
    "print(stop_words)\n",
    "\n",
    "# Display the total number of stopwords\n",
    "print(\"\\nTotal number of stopwords:\", len(stop_words))\n",
    "\n",
    "# Display a sample of stopwords\n",
    "print(\"\\nSample of stopwords:\", list(stop_words)[:20])\n",
    "\n",
    "\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize text into sentences, then words\n",
    "sentences = sent_tokenize(text)\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Print initial tokenized sentences (first 2 for brevity)\n",
    "print(\"Initial tokenized sentences (first 2 sentences):\")\n",
    "print(words[:2])\n",
    "\n",
    "# Flatten the list of words, remove stopwords, convert to lowercase, and lemmatize\n",
    "processed_words = [lemmatizer.lemmatize(w.lower()) for sentence in words for w in sentence if w.lower() not in stop_words and w.isalpha()]\n",
    "\n",
    "# Print each step for clarity\n",
    "print(\"\\nFlattened list of words:\")\n",
    "print([w for sentence in words for w in sentence][:20])  # Print first 20 words for brevity\n",
    "\n",
    "print(\"\\nLowercased and removed stopwords:\")\n",
    "print([w.lower() for sentence in words for w in sentence if w.lower() not in stop_words][:20])\n",
    "\n",
    "print(\"\\nLemmatized words (final processed list):\")\n",
    "print(processed_words[:20])  # Display the first 20 processed words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process the text\n",
    "processed_text = preprocess_text(text)\n",
    "print(\"Processed Text Sample:\", processed_text[:30])\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = Counter(processed_text)\n",
    "print(\"Word Frequency Sample:\", word_freq.most_common(10))\n",
    "\n",
    "# Convert to bag-of-words model using CountVectorizer\n",
    "def convert_to_bow(sentences):\n",
    "    vectorizer = CountVectorizer(analyzer='word', stop_words='english', lowercase=True)\n",
    "    bow_matrix = vectorizer.fit_transform(sentences)\n",
    "    return bow_matrix, vectorizer\n",
    "\n",
    "# Convert sentences to a bag-of-words representation\n",
    "sample_sentences = sent_tokenize(text)[:100]  # Taking first 100 sentences as a sample\n",
    "bow_matrix, vectorizer = convert_to_bow(sample_sentences)\n",
    "\n",
    "# Display vectorized representation\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out()[:10])\n",
    "print(\"Bag of Words Matrix Sample:\", bow_matrix.toarray()[:5])\n",
    "\n",
    "# Simple Naive Bayes Classification on Text Data\n",
    "# Generate a small mock dataset with labels (dummy labels for illustration)\n",
    "# Here, each sentence will be classified as either \"1\" or \"0\" randomly\n",
    "import random\n",
    "labels = [random.choice([0, 1]) for _ in range(len(sample_sentences))]\n",
    "\n",
    "# Split dataset into training and testing, making sure labels match sentences\n",
    "X_train, X_test, y_train, y_test, sentences_train, sentences_test = train_test_split(\n",
    "    bow_matrix, labels, sample_sentences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Classification Accuracy:\", accuracy)\n",
    "\n",
    "# Check that lengths match before DataFrame creation\n",
    "print(\"Length of sentences_test:\", len(sentences_test))\n",
    "print(\"Length of y_pred:\", len(y_pred))\n",
    "\n",
    "# Save predictions with matching lengths\n",
    "output = pd.DataFrame({\"sentence\": sentences_test, \"predicted_label\": y_pred})\n",
    "output.head()\n",
    "\n",
    "# Exporting the output to CSV for submission\n",
    "output.to_csv('nlp_assignment_output.csv', index=False)\n",
    "print(\"Output saved as 'nlp_assignment_output.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307895ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
